{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNHF0l0WhNyPj2BCpldUrnP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CM35S2pOFog","executionInfo":{"status":"ok","timestamp":1720974799043,"user_tz":-60,"elapsed":336,"user":{"displayName":"Ђорђе Живановић","userId":"06601775518800841362"}},"outputId":"0d7b26a1-8f0e-4b0d-e796-b8e07d1a769e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.          1.42000423  0.          2.11735258]\n"," [ 0.         -8.14697981  1.32102394  1.65555432]\n"," [ 0.          4.14556535  0.44267555  0.        ]\n"," [ 1.59474005  0.          0.         -9.28210201]\n"," [ 0.          0.          0.          0.        ]\n"," [ 0.1881      0.         -1.          0.        ]]\n"]}],"source":["import numpy as np\n","import random as rand\n","# Given a mouse, teach mouse to get all cheese and avoid death\n","# The following abbreviations are used: M - mouse, C - cheese,\n","# CC- big pile of cheese, E - empty field, P - poison\n","# M C E\n","# E P CC\n","\n","# 0. Read the link.\n","# 1. Change the table\n","# 2. Allows mouse to go diagonal\n","\n","def convert_2d_index_to_1d(two_dim_index: tuple, num_cols: int):\n","  return two_dim_index[0] * num_cols + two_dim_index[1]\n","\n","\n","def convert_1d_index_to_2d(two_dim_index: tuple, num_cols: int):\n","  return (two_dim_index[0] / num_cols, two_dim_index[1] % num_cols)\n","\n","\n","def is_pos_valid(cur_pos: tuple, num_rows: int, num_cols: int):\n","  return ((cur_pos[0] < num_rows) and (cur_pos[0] >= 0) and (cur_pos[1] < num_cols)\n","    and (cur_pos[1] >= 0))\n","\n","def compute_max_future_reward(Q, cur_state):\n","  return np.max(Q[cur_state, :])\n","\n","def tup_add(t1: tuple, t2: tuple):\n","  return (t1[0] + t2[0], t1[1] + t2[1])\n","\n","def episode_learn(num_rows, num_cols, alpha, gamma, Q, R, max_steps):\n","  cur_pos = (0, 0)\n","  final_pos = (1, 1)\n","\n","  actions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n","\n","  for i in range(max_steps):\n","    act_idx = rand.randint(0, 3)\n","    #print(act_idx)\n","    action = actions[act_idx]\n","    cur_pos_tmp = tup_add(cur_pos, action)\n","    if (not is_pos_valid(cur_pos_tmp, num_rows, num_cols)):\n","      continue\n","\n","    prev_pos = cur_pos\n","\n","    cur_pos = cur_pos_tmp\n","    prev_state = convert_2d_index_to_1d(prev_pos, num_cols)\n","    cur_state = convert_2d_index_to_1d(cur_pos, num_cols)\n","    #print(\"cur_state\", cur_state, cur_pos)\n","    #print(\"R\", R[cur_state], prev_pos, cur_pos)\n","    q_new = (1 - alpha) * Q[prev_state, act_idx] + \\\n","      alpha * (R[cur_state] + gamma * compute_max_future_reward(Q, cur_state))\n","    Q[prev_state, act_idx] = q_new\n","    if cur_pos == final_pos:\n","      break\n","\n","def learn(num_rows: int, num_cols: int, rewards: list, alpha: int, gamma: int):\n","\n","  max_steps = 5\n","  num_states = num_rows * num_cols\n","  # This variable list all potential moves the mouse can make from one state\n","  num_moves = 4\n","  # The Q-value evaluation matrix\n","  Q = np.zeros((num_states, num_moves))\n","  # Reward for each state\n","  R = rewards\n","\n","  for i in range(100):\n","    episode_learn(num_rows, num_cols, alpha, gamma, Q, R, max_steps)\n","  print(Q)\n","\n","\n","# This variable lists potential states which the mouse can occupy\n","num_rows = 2\n","num_cols = 3\n","# Reward for each state\n","rewards = [0, 1, 0, 0, -10, 10]\n","# learning rate\n","alpha = 0.1\n","gamma = 0.99\n","\n","\n","learn(num_rows, num_cols, rewards, alpha, gamma)\n"]}]}