{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNbsqvLZK6W2+WPY39hzdTa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Dhrvwg6m8E5v","outputId":"aaefd7e4-e30f-4961-f037-a56663ccd032","executionInfo":{"status":"error","timestamp":1723730989876,"user_tz":-60,"elapsed":533678,"user":{"displayName":"Ђорђе Живановић","userId":"06601775518800841362"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:02<00:00, 3787996.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 447432.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 4062710.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 5813405.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.1717544  -0.14712608 -0.06462049]\n","  [ 0.15645632 -0.31381232  0.19990575]\n","  [-0.06857511  0.1695813   0.046339  ]]]\n","[[[-0.04081472  0.09245364  0.01644393]\n","  [ 0.12174273 -0.12990034 -0.02430292]\n","  [-0.03000911  0.04831465 -0.00133161]]]\n","[[[ 0.29138893  0.10373005 -0.12413542]\n","  [-0.20132045 -0.05587189 -0.14378023]\n","  [-0.10681617  0.01596054  0.19870925]]]\n","[[[ 0.1811789  -0.3258503   0.20664017]\n","  [ 0.09312129  0.31618518  0.22001994]\n","  [-0.30371258 -0.31693614 -0.16077738]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.1717544  -0.14712608 -0.06462049]\n","  [ 0.15645632 -0.31381232  0.19990575]\n","  [-0.06857511  0.1695813   0.046339  ]]]\n","[[[-0.04081472  0.09245364  0.01644393]\n","  [ 0.12174273 -0.12990034 -0.02430292]\n","  [-0.03000911  0.04831465 -0.00133161]]]\n","[[[ 0.29138893  0.10373005 -0.12413542]\n","  [-0.20132045 -0.05587189 -0.14378023]\n","  [-0.10681617  0.01596054  0.19870925]]]\n","[[[ 0.1811789  -0.3258503   0.20664017]\n","  [ 0.09312129  0.31618518  0.22001994]\n","  [-0.30371258 -0.31693614 -0.16077738]]]\n","Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.295584\n","Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.717248\n","Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.681445\n","Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.704781\n","Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.533413\n","Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.472336\n","Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.402518\n","Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.252276\n","Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.162294\n","Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.163024\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.313995\n","Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.217019\n","Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.304571\n","Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.223912\n","Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.109837\n","Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.144742\n","Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.178982\n","Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.130440\n","Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.120855\n","Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.314789\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.188360\n","Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.202071\n","Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.215435\n","Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.049329\n","Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.134322\n","Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.288579\n","Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.198284\n","Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.060723\n","Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.080267\n","Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.147559\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.083192\n","Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.058587\n","Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.267161\n","Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.099234\n","Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.244457\n","Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.187828\n","Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.138187\n","Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.028308\n","Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.091540\n","Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.137939\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.112334\n","Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.150150\n","Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.141078\n","Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.153195\n","Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.304472\n","Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.151083\n","Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.020989\n","Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.194572\n","Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.033225\n","Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.048745\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.135397\n","Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.194467\n","Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.175873\n","Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.037629\n","Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.081025\n","Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.062821\n","Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.112547\n","Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.142387\n","Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.079512\n","Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.046460\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.108791\n","Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.121474\n","Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.080731\n","Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.012421\n","Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.112766\n","Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.202072\n","Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.073668\n","Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.123112\n","Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.038933\n","Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.120785\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.078183\n","Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.183545\n","Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.033490\n","Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.033077\n","Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.150917\n","Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.059736\n","Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.148758\n","Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.343918\n","Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.199098\n","Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.015941\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.243965\n","Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.351546\n","Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.206088\n","Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.022294\n","Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.100641\n","Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.182433\n","Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.098804\n","Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.068349\n","Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.082543\n","Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.028826\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.135314\n","Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.072338\n","Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.048600\n","Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.119008\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.19736074 -0.19652854 -0.23056053]\n","  [ 0.14390329 -0.29923502  0.19638354]\n","  [-0.09008171  0.23902975  0.11736953]]]\n","[[[-0.07706589  0.08950329  0.05733289]\n","  [ 0.07243204 -0.14239655 -0.08986971]\n","  [-0.11395863  0.02683629 -0.05478466]]]\n","[[[ 0.32785812  0.10774592 -0.1806237 ]\n","  [-0.22057945 -0.17853591 -0.26060784]\n","  [-0.18299113 -0.00157134  0.25616422]]]\n","[[[ 0.19948933 -0.25566247  0.26731807]\n","  [ 0.0794856   0.3423095   0.24654098]\n","  [-0.40158358 -0.43369994 -0.26002115]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.19736074 -0.19652854 -0.23056053]\n","  [ 0.14390329 -0.29923502  0.19638354]\n","  [-0.09008171  0.23902975  0.11736953]]]\n","[[[-0.07706589  0.08950329  0.05733289]\n","  [ 0.07243204 -0.14239655 -0.08986971]\n","  [-0.11395863  0.02683629 -0.05478466]]]\n","[[[ 0.32785812  0.10774592 -0.1806237 ]\n","  [-0.22057945 -0.17853591 -0.26060784]\n","  [-0.18299113 -0.00157134  0.25616422]]]\n","[[[ 0.19948933 -0.25566247  0.26731807]\n","  [ 0.0794856   0.3423095   0.24654098]\n","  [-0.40158358 -0.43369994 -0.26002115]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.19736074 -0.19652854 -0.23056053]\n","  [ 0.14390329 -0.29923502  0.19638354]\n","  [-0.09008171  0.23902975  0.11736953]]]\n","[[[-0.07706589  0.08950329  0.05733289]\n","  [ 0.07243204 -0.14239655 -0.08986971]\n","  [-0.11395863  0.02683629 -0.05478466]]]\n","[[[ 0.32785812  0.10774592 -0.1806237 ]\n","  [-0.22057945 -0.17853591 -0.26060784]\n","  [-0.18299113 -0.00157134  0.25616422]]]\n","[[[ 0.19948933 -0.25566247  0.26731807]\n","  [ 0.0794856   0.3423095   0.24654098]\n","  [-0.40158358 -0.43369994 -0.26002115]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.19736074 -0.19652854 -0.23056053]\n","  [ 0.14390329 -0.29923502  0.19638354]\n","  [-0.09008171  0.23902975  0.11736953]]]\n","[[[-0.07706589  0.08950329  0.05733289]\n","  [ 0.07243204 -0.14239655 -0.08986971]\n","  [-0.11395863  0.02683629 -0.05478466]]]\n","[[[ 0.32785812  0.10774592 -0.1806237 ]\n","  [-0.22057945 -0.17853591 -0.26060784]\n","  [-0.18299113 -0.00157134  0.25616422]]]\n","[[[ 0.19948933 -0.25566247  0.26731807]\n","  [ 0.0794856   0.3423095   0.24654098]\n","  [-0.40158358 -0.43369994 -0.26002115]]]\n","\n","Test set: Average loss: 0.0562, Accuracy: 9807/10000 (98%)\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.177360\n","Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.142452\n","Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.122619\n","Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.037560\n","Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.019381\n","Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.118888\n","Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.105139\n","Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.049438\n","Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.045422\n","Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.024003\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.051354\n","Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.047371\n","Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.054521\n","Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.079320\n","Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.097001\n","Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.042969\n","Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.040010\n","Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.054852\n","Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.125959\n","Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.170795\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.098958\n","Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.019656\n","Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.135841\n","Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.041254\n","Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.021054\n","Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.048740\n","Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.043245\n","Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.153067\n","Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.055297\n","Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.079993\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.173118\n","Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.054836\n","Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.027673\n","Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.069049\n","Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.076441\n","Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.139381\n","Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.196317\n","Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.029326\n","Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.017810\n","Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.003777\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.011070\n","Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.009859\n","Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.009641\n","Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.130208\n","Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.153842\n","Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.031587\n","Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.053169\n","Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.116725\n","Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.006501\n","Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.029413\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.017558\n","Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.017047\n","Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.221876\n","Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.130726\n","Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.086131\n","Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.122688\n","Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.126601\n","Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.060715\n","Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.060372\n","Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.112424\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.044666\n","Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.031781\n","Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.031192\n","Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.154260\n","Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.074946\n","Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.016090\n","Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.005929\n","Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.134953\n","Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.031069\n","Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.148152\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.159345\n","Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.075093\n","Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.097897\n","Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.043406\n","Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.161630\n","Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.010036\n","Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.012020\n","Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.034510\n","Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.013450\n","Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.044888\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.014746\n","Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.059047\n","Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.006275\n","Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.152843\n","Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.035133\n","Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.011222\n","Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.101001\n","Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.025315\n","Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.061052\n","Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.013398\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.002642\n","Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.078434\n","Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.075092\n","Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.035903\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.22895716 -0.15691282 -0.24152738]\n","  [ 0.14713724 -0.31985456  0.17766   ]\n","  [-0.10825316  0.20725322  0.10393029]]]\n","[[[-0.06088344  0.10484827  0.09872808]\n","  [ 0.07810357 -0.14627777 -0.08325209]\n","  [-0.10988158  0.02849509 -0.05096859]]]\n","[[[ 0.3547997   0.14245665 -0.15627736]\n","  [-0.21751404 -0.1726442  -0.24545707]\n","  [-0.17247845  0.01292923  0.27174878]]]\n","[[[ 0.16409026 -0.27081895  0.27380812]\n","  [ 0.03297777  0.33402354  0.26253054]\n","  [-0.42818603 -0.47164485 -0.26094636]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.22895716 -0.15691282 -0.24152738]\n","  [ 0.14713724 -0.31985456  0.17766   ]\n","  [-0.10825316  0.20725322  0.10393029]]]\n","[[[-0.06088344  0.10484827  0.09872808]\n","  [ 0.07810357 -0.14627777 -0.08325209]\n","  [-0.10988158  0.02849509 -0.05096859]]]\n","[[[ 0.3547997   0.14245665 -0.15627736]\n","  [-0.21751404 -0.1726442  -0.24545707]\n","  [-0.17247845  0.01292923  0.27174878]]]\n","[[[ 0.16409026 -0.27081895  0.27380812]\n","  [ 0.03297777  0.33402354  0.26253054]\n","  [-0.42818603 -0.47164485 -0.26094636]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.22895716 -0.15691282 -0.24152738]\n","  [ 0.14713724 -0.31985456  0.17766   ]\n","  [-0.10825316  0.20725322  0.10393029]]]\n","[[[-0.06088344  0.10484827  0.09872808]\n","  [ 0.07810357 -0.14627777 -0.08325209]\n","  [-0.10988158  0.02849509 -0.05096859]]]\n","[[[ 0.3547997   0.14245665 -0.15627736]\n","  [-0.21751404 -0.1726442  -0.24545707]\n","  [-0.17247845  0.01292923  0.27174878]]]\n","[[[ 0.16409026 -0.27081895  0.27380812]\n","  [ 0.03297777  0.33402354  0.26253054]\n","  [-0.42818603 -0.47164485 -0.26094636]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.22895716 -0.15691282 -0.24152738]\n","  [ 0.14713724 -0.31985456  0.17766   ]\n","  [-0.10825316  0.20725322  0.10393029]]]\n","[[[-0.06088344  0.10484827  0.09872808]\n","  [ 0.07810357 -0.14627777 -0.08325209]\n","  [-0.10988158  0.02849509 -0.05096859]]]\n","[[[ 0.3547997   0.14245665 -0.15627736]\n","  [-0.21751404 -0.1726442  -0.24545707]\n","  [-0.17247845  0.01292923  0.27174878]]]\n","[[[ 0.16409026 -0.27081895  0.27380812]\n","  [ 0.03297777  0.33402354  0.26253054]\n","  [-0.42818603 -0.47164485 -0.26094636]]]\n","\n","Test set: Average loss: 0.0407, Accuracy: 9860/10000 (99%)\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.019003\n","Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.005950\n","Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.025982\n","Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.109196\n","Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.106658\n","Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.015889\n","Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.009084\n","Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.049377\n","Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.126537\n","Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.034794\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.017448\n","Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.118955\n","Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.057175\n","Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.008266\n","Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.045675\n","Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.005515\n","Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.024122\n","Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.004809\n","Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.028599\n","Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.003062\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.015396\n","Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.001255\n","Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.022789\n","Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.031849\n","Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.017713\n","Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.012156\n","Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.010975\n","Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.058337\n","Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.102178\n","Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.179984\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.045597\n","Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.093928\n","Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.002327\n","Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.020615\n","Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.034330\n","Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.046050\n","Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.263280\n","Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.091808\n","Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.004829\n","Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.115035\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.008896\n","Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.010140\n","Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.056557\n","Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.096758\n","Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.063720\n","Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.073795\n","Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.110868\n","Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.083842\n","Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.203299\n","Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.043150\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.018455\n","Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.012882\n","Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.024901\n","Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.099429\n","Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.034523\n","Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.016216\n","Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.009885\n","Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.065066\n","Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.018161\n","Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.107366\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.022592\n","Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.020781\n","Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.013827\n","Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.077711\n","Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.015786\n","Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.047029\n","Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.010812\n","Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.007441\n","Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.012943\n","Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.112424\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.004375\n","Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.002544\n","Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.010212\n","Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.023327\n","Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.047168\n","Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.012068\n","Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.028256\n","Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.053993\n","Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.169208\n","Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.053858\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.077641\n","Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.023321\n","Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.004757\n","Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.024970\n","Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.002827\n","Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.048437\n","Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.110322\n","Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.104217\n","Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.023863\n","Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.004305\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.002360\n","Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.119267\n","Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.016486\n","Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.076890\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.21978697 -0.1732772  -0.22770981]\n","  [ 0.14429668 -0.3223565   0.19134478]\n","  [-0.11975115  0.19991411  0.11254833]]]\n","[[[-0.07524706  0.09455448  0.08384874]\n","  [ 0.07154106 -0.17075065 -0.1097347 ]\n","  [-0.12835148  0.00097686 -0.07955012]]]\n","[[[ 0.3272817   0.11579264 -0.16309886]\n","  [-0.24635917 -0.20668821 -0.2403106 ]\n","  [-0.18376754  0.01272149  0.29462665]]]\n","[[[ 0.18734522 -0.26294762  0.26201898]\n","  [ 0.04030174  0.32711896  0.24562867]\n","  [-0.42628852 -0.5088956  -0.28535265]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.21978697 -0.1732772  -0.22770981]\n","  [ 0.14429668 -0.3223565   0.19134478]\n","  [-0.11975115  0.19991411  0.11254833]]]\n","[[[-0.07524706  0.09455448  0.08384874]\n","  [ 0.07154106 -0.17075065 -0.1097347 ]\n","  [-0.12835148  0.00097686 -0.07955012]]]\n","[[[ 0.3272817   0.11579264 -0.16309886]\n","  [-0.24635917 -0.20668821 -0.2403106 ]\n","  [-0.18376754  0.01272149  0.29462665]]]\n","[[[ 0.18734522 -0.26294762  0.26201898]\n","  [ 0.04030174  0.32711896  0.24562867]\n","  [-0.42628852 -0.5088956  -0.28535265]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.21978697 -0.1732772  -0.22770981]\n","  [ 0.14429668 -0.3223565   0.19134478]\n","  [-0.11975115  0.19991411  0.11254833]]]\n","[[[-0.07524706  0.09455448  0.08384874]\n","  [ 0.07154106 -0.17075065 -0.1097347 ]\n","  [-0.12835148  0.00097686 -0.07955012]]]\n","[[[ 0.3272817   0.11579264 -0.16309886]\n","  [-0.24635917 -0.20668821 -0.2403106 ]\n","  [-0.18376754  0.01272149  0.29462665]]]\n","[[[ 0.18734522 -0.26294762  0.26201898]\n","  [ 0.04030174  0.32711896  0.24562867]\n","  [-0.42628852 -0.5088956  -0.28535265]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.21978697 -0.1732772  -0.22770981]\n","  [ 0.14429668 -0.3223565   0.19134478]\n","  [-0.11975115  0.19991411  0.11254833]]]\n","[[[-0.07524706  0.09455448  0.08384874]\n","  [ 0.07154106 -0.17075065 -0.1097347 ]\n","  [-0.12835148  0.00097686 -0.07955012]]]\n","[[[ 0.3272817   0.11579264 -0.16309886]\n","  [-0.24635917 -0.20668821 -0.2403106 ]\n","  [-0.18376754  0.01272149  0.29462665]]]\n","[[[ 0.18734522 -0.26294762  0.26201898]\n","  [ 0.04030174  0.32711896  0.24562867]\n","  [-0.42628852 -0.5088956  -0.28535265]]]\n","\n","Test set: Average loss: 0.0333, Accuracy: 9880/10000 (99%)\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.153951\n","Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.009081\n","Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.004492\n","Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.001357\n","Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.183265\n","Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.105164\n","Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.091377\n","Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.069894\n","Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.003496\n","Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.001460\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.017308\n","Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.066502\n","Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.098969\n","Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.068142\n","Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.015805\n","Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.002920\n","Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.003197\n","Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.104573\n","Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.007462\n","Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.173773\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.161746\n","Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.021704\n","Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.036437\n","Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.000685\n","Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.027057\n","Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.008434\n","Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.004798\n","Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.037694\n","Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.102294\n","Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.006460\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.008287\n","Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.071275\n","Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.127902\n","Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.015421\n","Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.015702\n","Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.003692\n","Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.043226\n","Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.011383\n","Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.053463\n","Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.095841\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.090008\n","Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.003031\n","Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.030267\n","Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.007473\n","Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.014284\n","Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.066011\n","Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.027386\n","Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.091037\n","Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.008402\n","Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.055807\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.020399\n","Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.250045\n","Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.003013\n","Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.004842\n","Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.013944\n","Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.220911\n","Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.014114\n","Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.007848\n","Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.040089\n","Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.062564\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.016269\n","Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.024668\n","Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.041104\n","Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.043272\n","Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.065757\n","Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.058835\n","Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.011382\n","Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.049525\n","Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.022147\n","Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.081377\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.008504\n","Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.003914\n","Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.102463\n","Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.025322\n","Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.023785\n","Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.012517\n","Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.009541\n","Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.106503\n","Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.012350\n","Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.175665\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.134392\n","Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.008867\n","Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.058981\n","Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.099344\n","Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.011572\n","Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.027221\n","Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.053595\n","Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.050178\n","Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.133017\n","Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.034500\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.007354\n","Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.020474\n","Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.079124\n","Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.009703\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.23419327 -0.16697648 -0.22915792]\n","  [ 0.15329376 -0.32895124  0.19206801]\n","  [-0.1137067   0.20206589  0.11565475]]]\n","[[[-0.07694017  0.09531547  0.09371576]\n","  [ 0.07518694 -0.18259548 -0.11480951]\n","  [-0.12840098 -0.00364052 -0.08140089]]]\n","[[[ 0.35240704  0.13871899 -0.15409389]\n","  [-0.22279435 -0.19588785 -0.23313631]\n","  [-0.17612974  0.01649994  0.30401954]]]\n","[[[ 0.17887561 -0.26514855  0.26671916]\n","  [ 0.0404678   0.3225373   0.2521232 ]\n","  [-0.4323615  -0.51972497 -0.27645808]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.23419327 -0.16697648 -0.22915792]\n","  [ 0.15329376 -0.32895124  0.19206801]\n","  [-0.1137067   0.20206589  0.11565475]]]\n","[[[-0.07694017  0.09531547  0.09371576]\n","  [ 0.07518694 -0.18259548 -0.11480951]\n","  [-0.12840098 -0.00364052 -0.08140089]]]\n","[[[ 0.35240704  0.13871899 -0.15409389]\n","  [-0.22279435 -0.19588785 -0.23313631]\n","  [-0.17612974  0.01649994  0.30401954]]]\n","[[[ 0.17887561 -0.26514855  0.26671916]\n","  [ 0.0404678   0.3225373   0.2521232 ]\n","  [-0.4323615  -0.51972497 -0.27645808]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.23419327 -0.16697648 -0.22915792]\n","  [ 0.15329376 -0.32895124  0.19206801]\n","  [-0.1137067   0.20206589  0.11565475]]]\n","[[[-0.07694017  0.09531547  0.09371576]\n","  [ 0.07518694 -0.18259548 -0.11480951]\n","  [-0.12840098 -0.00364052 -0.08140089]]]\n","[[[ 0.35240704  0.13871899 -0.15409389]\n","  [-0.22279435 -0.19588785 -0.23313631]\n","  [-0.17612974  0.01649994  0.30401954]]]\n","[[[ 0.17887561 -0.26514855  0.26671916]\n","  [ 0.0404678   0.3225373   0.2521232 ]\n","  [-0.4323615  -0.51972497 -0.27645808]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.23419327 -0.16697648 -0.22915792]\n","  [ 0.15329376 -0.32895124  0.19206801]\n","  [-0.1137067   0.20206589  0.11565475]]]\n","[[[-0.07694017  0.09531547  0.09371576]\n","  [ 0.07518694 -0.18259548 -0.11480951]\n","  [-0.12840098 -0.00364052 -0.08140089]]]\n","[[[ 0.35240704  0.13871899 -0.15409389]\n","  [-0.22279435 -0.19588785 -0.23313631]\n","  [-0.17612974  0.01649994  0.30401954]]]\n","[[[ 0.17887561 -0.26514855  0.26671916]\n","  [ 0.0404678   0.3225373   0.2521232 ]\n","  [-0.4323615  -0.51972497 -0.27645808]]]\n","\n","Test set: Average loss: 0.0272, Accuracy: 9902/10000 (99%)\n","\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.000529\n","Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.010287\n","Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.005535\n","Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.025357\n","Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.210970\n","Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.006566\n","Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.029251\n","Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.010786\n","Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.003970\n","Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.057231\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.039232\n","Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.052522\n","Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.023890\n","Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.018872\n","Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.051526\n","Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.008291\n","Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.157258\n","Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.000834\n","Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.151074\n","Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.100056\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.182132\n","Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.037278\n","Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.052883\n","Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.026545\n","Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.025583\n","Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.090637\n","Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.039587\n","Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.005300\n","Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.031897\n","Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.069859\n","Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.034480\n","Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.024701\n","Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.051756\n","Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.049677\n","Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.106745\n","Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.001258\n","Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.007878\n","Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.011804\n","Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.004159\n","Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.052891\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.022111\n","Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.034200\n","Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.082456\n","Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.008133\n","Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.028510\n","Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.090535\n","Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.051757\n","Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.004357\n","Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.093655\n","Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.001658\n","Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.001065\n","Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.015738\n","Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.008915\n","Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.126494\n","Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.016144\n","Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.023270\n","Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.007771\n","Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.027735\n","Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.058122\n","Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.016153\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.015585\n","Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.018524\n","Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.010276\n","Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.004587\n","Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.162677\n","Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.072806\n","Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.005789\n","Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.116114\n","Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.009862\n","Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.001425\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.006206\n","Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.028143\n","Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.006621\n","Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.008733\n","Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.068445\n","Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.038042\n","Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.037047\n","Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.058199\n","Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.005770\n","Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.045461\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.084353\n","Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.002793\n","Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.010915\n","Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.100702\n","Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.004278\n","Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.026270\n","Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.009918\n","Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.011743\n","Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.120996\n","Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.056952\n","Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.007707\n","Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.183250\n","Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.024971\n","Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.015798\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.22920024 -0.17757675 -0.22801511]\n","  [ 0.14809251 -0.33139998  0.19537556]\n","  [-0.11430147  0.20049909  0.11830162]]]\n","[[[-0.07267677  0.09689317  0.10379148]\n","  [ 0.07356662 -0.1861866  -0.11943725]\n","  [-0.1372549  -0.01132507 -0.08787586]]]\n","[[[ 0.35075483  0.13629998 -0.15634422]\n","  [-0.22023478 -0.18972918 -0.23950252]\n","  [-0.17223848  0.01916741  0.30225638]]]\n","[[[ 0.18469974 -0.26127502  0.27404875]\n","  [ 0.03836948  0.32235226  0.25793645]\n","  [-0.42884052 -0.51922256 -0.2728513 ]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.22920024 -0.17757675 -0.22801511]\n","  [ 0.14809251 -0.33139998  0.19537556]\n","  [-0.11430147  0.20049909  0.11830162]]]\n","[[[-0.07267677  0.09689317  0.10379148]\n","  [ 0.07356662 -0.1861866  -0.11943725]\n","  [-0.1372549  -0.01132507 -0.08787586]]]\n","[[[ 0.35075483  0.13629998 -0.15634422]\n","  [-0.22023478 -0.18972918 -0.23950252]\n","  [-0.17223848  0.01916741  0.30225638]]]\n","[[[ 0.18469974 -0.26127502  0.27404875]\n","  [ 0.03836948  0.32235226  0.25793645]\n","  [-0.42884052 -0.51922256 -0.2728513 ]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.22920024 -0.17757675 -0.22801511]\n","  [ 0.14809251 -0.33139998  0.19537556]\n","  [-0.11430147  0.20049909  0.11830162]]]\n","[[[-0.07267677  0.09689317  0.10379148]\n","  [ 0.07356662 -0.1861866  -0.11943725]\n","  [-0.1372549  -0.01132507 -0.08787586]]]\n","[[[ 0.35075483  0.13629998 -0.15634422]\n","  [-0.22023478 -0.18972918 -0.23950252]\n","  [-0.17223848  0.01916741  0.30225638]]]\n","[[[ 0.18469974 -0.26127502  0.27404875]\n","  [ 0.03836948  0.32235226  0.25793645]\n","  [-0.42884052 -0.51922256 -0.2728513 ]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.22920024 -0.17757675 -0.22801511]\n","  [ 0.14809251 -0.33139998  0.19537556]\n","  [-0.11430147  0.20049909  0.11830162]]]\n","[[[-0.07267677  0.09689317  0.10379148]\n","  [ 0.07356662 -0.1861866  -0.11943725]\n","  [-0.1372549  -0.01132507 -0.08787586]]]\n","[[[ 0.35075483  0.13629998 -0.15634422]\n","  [-0.22023478 -0.18972918 -0.23950252]\n","  [-0.17223848  0.01916741  0.30225638]]]\n","[[[ 0.18469974 -0.26127502  0.27404875]\n","  [ 0.03836948  0.32235226  0.25793645]\n","  [-0.42884052 -0.51922256 -0.2728513 ]]]\n","\n","Test set: Average loss: 0.0283, Accuracy: 9906/10000 (99%)\n","\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.000677\n","Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.004456\n","Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.001328\n","Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.048374\n","Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.011584\n","Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.015163\n","Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.002596\n","Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.044375\n","Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.002757\n","Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.037401\n","Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.023931\n","Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.014777\n","Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.046272\n","Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.113601\n","Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.010584\n","Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.023073\n","Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.002766\n","Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.003510\n","Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.004750\n","Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.025902\n","Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.004415\n","Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.047420\n","Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.018077\n","Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.072451\n","Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.004614\n","Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.012198\n","Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.041118\n","Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.003306\n","Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.053806\n","Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.045200\n","Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.004931\n","Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.026114\n","Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.007042\n","Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.017071\n","Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.004099\n","Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.010446\n","Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.028600\n","Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.051958\n","Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.022790\n","Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.019535\n","Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.002926\n","Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.013360\n","Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.031397\n","Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.027863\n","Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.015817\n","Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.006394\n","Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.001240\n","Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.059727\n","Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.056736\n","Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.063929\n","Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.061788\n","Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.026028\n","Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.139992\n","Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.058668\n","Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.025778\n","Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.025714\n","Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.077828\n","Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.009784\n","Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.164420\n","Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.002573\n","Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.008518\n","Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.038651\n","Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.013047\n","Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.008344\n","Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.120289\n","Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.020923\n","Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.015077\n","Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.106619\n","Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.100214\n","Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.066367\n","Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.038806\n","Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.020656\n","Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.001046\n","Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.009285\n","Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.019706\n","Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.009044\n","Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.013509\n","Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.005154\n","Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.036739\n","Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.041387\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.007269\n","Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.067753\n","Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.027620\n","Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.087189\n","Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.014850\n","Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.002133\n","Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.036849\n","Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.230296\n","Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.039475\n","Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.036298\n","Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.020415\n","Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.161564\n","Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.003786\n","Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.004859\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.2287282  -0.17595628 -0.22658217]\n","  [ 0.14793749 -0.33117655  0.19206178]\n","  [-0.11573607  0.19496863  0.11071814]]]\n","[[[-0.07654591  0.09583738  0.10411286]\n","  [ 0.06815444 -0.19458947 -0.12847947]\n","  [-0.14854182 -0.02224921 -0.09816384]]]\n","[[[ 0.35804653  0.13624477 -0.162979  ]\n","  [-0.2161837  -0.18731605 -0.23884721]\n","  [-0.16954751  0.02441534  0.30722678]]]\n","[[[ 0.18952936 -0.25601146  0.27489147]\n","  [ 0.04294372  0.32516912  0.25442502]\n","  [-0.43129206 -0.52574533 -0.28149828]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.2287282  -0.17595628 -0.22658217]\n","  [ 0.14793749 -0.33117655  0.19206178]\n","  [-0.11573607  0.19496863  0.11071814]]]\n","[[[-0.07654591  0.09583738  0.10411286]\n","  [ 0.06815444 -0.19458947 -0.12847947]\n","  [-0.14854182 -0.02224921 -0.09816384]]]\n","[[[ 0.35804653  0.13624477 -0.162979  ]\n","  [-0.2161837  -0.18731605 -0.23884721]\n","  [-0.16954751  0.02441534  0.30722678]]]\n","[[[ 0.18952936 -0.25601146  0.27489147]\n","  [ 0.04294372  0.32516912  0.25442502]\n","  [-0.43129206 -0.52574533 -0.28149828]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.2287282  -0.17595628 -0.22658217]\n","  [ 0.14793749 -0.33117655  0.19206178]\n","  [-0.11573607  0.19496863  0.11071814]]]\n","[[[-0.07654591  0.09583738  0.10411286]\n","  [ 0.06815444 -0.19458947 -0.12847947]\n","  [-0.14854182 -0.02224921 -0.09816384]]]\n","[[[ 0.35804653  0.13624477 -0.162979  ]\n","  [-0.2161837  -0.18731605 -0.23884721]\n","  [-0.16954751  0.02441534  0.30722678]]]\n","[[[ 0.18952936 -0.25601146  0.27489147]\n","  [ 0.04294372  0.32516912  0.25442502]\n","  [-0.43129206 -0.52574533 -0.28149828]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.2287282  -0.17595628 -0.22658217]\n","  [ 0.14793749 -0.33117655  0.19206178]\n","  [-0.11573607  0.19496863  0.11071814]]]\n","[[[-0.07654591  0.09583738  0.10411286]\n","  [ 0.06815444 -0.19458947 -0.12847947]\n","  [-0.14854182 -0.02224921 -0.09816384]]]\n","[[[ 0.35804653  0.13624477 -0.162979  ]\n","  [-0.2161837  -0.18731605 -0.23884721]\n","  [-0.16954751  0.02441534  0.30722678]]]\n","[[[ 0.18952936 -0.25601146  0.27489147]\n","  [ 0.04294372  0.32516912  0.25442502]\n","  [-0.43129206 -0.52574533 -0.28149828]]]\n","\n","Test set: Average loss: 0.0282, Accuracy: 9903/10000 (99%)\n","\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.007708\n","Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.064403\n","Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.043981\n","Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.042800\n","Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.020139\n","Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.045796\n","Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.065084\n","Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.000711\n","Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.002434\n","Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.041682\n","Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.058107\n","Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.010861\n","Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.002709\n","Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.002983\n","Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.003112\n","Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.002632\n","Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.024024\n","Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.013630\n","Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.053511\n","Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.000869\n","Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.028750\n","Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.026150\n","Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.064603\n","Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.009385\n","Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.003922\n","Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.057276\n","Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.028337\n","Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.102073\n","Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.008029\n","Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.012327\n","Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.028477\n","Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.000961\n","Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.006719\n","Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.056794\n","Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.076318\n","Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.043539\n","Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.087350\n","Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.003586\n","Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.017486\n","Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.047976\n","Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.014091\n","Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.010226\n","Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.007697\n","Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.016119\n","Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.001006\n","Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.013478\n","Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.129169\n","Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.007172\n","Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.001023\n","Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.012179\n","Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.005599\n","Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.040832\n","Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.023801\n","Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.017735\n","Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.003568\n","Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.065958\n","Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.153867\n","Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.002546\n","Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.015624\n","Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.001557\n","Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.014979\n","Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.002459\n","Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.038914\n","Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.003297\n","Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.044100\n","Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.007207\n","Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.010821\n","Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.031763\n","Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.110839\n","Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.004511\n","Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.002395\n","Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.016183\n","Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.324250\n","Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.023213\n","Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.016041\n","Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.028710\n","Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.022880\n","Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.015984\n","Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.005465\n","Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.006703\n","Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.009509\n","Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.016946\n","Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.000711\n","Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.042492\n","Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.005588\n","Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.007773\n","Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.002005\n","Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.022589\n","Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.017988\n","Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.060080\n","Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.001784\n","Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.004482\n","Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.018571\n","Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.005172\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.23189262 -0.17433558 -0.22519477]\n","  [ 0.15277627 -0.32516822  0.19633617]\n","  [-0.11135843  0.20247933  0.11772394]]]\n","[[[-0.07622538  0.09681566  0.10726627]\n","  [ 0.06668824 -0.19689831 -0.13015892]\n","  [-0.1505344  -0.02467436 -0.10044315]]]\n","[[[ 0.357083    0.13697568 -0.16022585]\n","  [-0.22099479 -0.18822289 -0.2355008 ]\n","  [-0.17511581  0.02293469  0.3109743 ]]]\n","[[[ 0.18928489 -0.25859287  0.2728805 ]\n","  [ 0.04534408  0.32317358  0.254526  ]\n","  [-0.4284693  -0.5260504  -0.2795164 ]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.23189262 -0.17433558 -0.22519477]\n","  [ 0.15277627 -0.32516822  0.19633617]\n","  [-0.11135843  0.20247933  0.11772394]]]\n","[[[-0.07622538  0.09681566  0.10726627]\n","  [ 0.06668824 -0.19689831 -0.13015892]\n","  [-0.1505344  -0.02467436 -0.10044315]]]\n","[[[ 0.357083    0.13697568 -0.16022585]\n","  [-0.22099479 -0.18822289 -0.2355008 ]\n","  [-0.17511581  0.02293469  0.3109743 ]]]\n","[[[ 0.18928489 -0.25859287  0.2728805 ]\n","  [ 0.04534408  0.32317358  0.254526  ]\n","  [-0.4284693  -0.5260504  -0.2795164 ]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.23189262 -0.17433558 -0.22519477]\n","  [ 0.15277627 -0.32516822  0.19633617]\n","  [-0.11135843  0.20247933  0.11772394]]]\n","[[[-0.07622538  0.09681566  0.10726627]\n","  [ 0.06668824 -0.19689831 -0.13015892]\n","  [-0.1505344  -0.02467436 -0.10044315]]]\n","[[[ 0.357083    0.13697568 -0.16022585]\n","  [-0.22099479 -0.18822289 -0.2355008 ]\n","  [-0.17511581  0.02293469  0.3109743 ]]]\n","[[[ 0.18928489 -0.25859287  0.2728805 ]\n","  [ 0.04534408  0.32317358  0.254526  ]\n","  [-0.4284693  -0.5260504  -0.2795164 ]]]\n","AFTER CONV SHAPE torch.Size([1000, 32, 26, 26])\n","torch.float32\n","torch.Size([32, 1, 3, 3])\n","[[[ 0.23189262 -0.17433558 -0.22519477]\n","  [ 0.15277627 -0.32516822  0.19633617]\n","  [-0.11135843  0.20247933  0.11772394]]]\n","[[[-0.07622538  0.09681566  0.10726627]\n","  [ 0.06668824 -0.19689831 -0.13015892]\n","  [-0.1505344  -0.02467436 -0.10044315]]]\n","[[[ 0.357083    0.13697568 -0.16022585]\n","  [-0.22099479 -0.18822289 -0.2355008 ]\n","  [-0.17511581  0.02293469  0.3109743 ]]]\n","[[[ 0.18928489 -0.25859287  0.2728805 ]\n","  [ 0.04534408  0.32317358  0.254526  ]\n","  [-0.4284693  -0.5260504  -0.2795164 ]]]\n","\n","Test set: Average loss: 0.0282, Accuracy: 9905/10000 (99%)\n","\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.013874\n","Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.010188\n","Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.053332\n","Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.025454\n","Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.003239\n","Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.025210\n","Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.005728\n","Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.008483\n","Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.001143\n","Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.019126\n","Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.019672\n","Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.148834\n","Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.024344\n","Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.014429\n","Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.080888\n","Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.016625\n","Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.039382\n","Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.003196\n","Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.002224\n","Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.007654\n","Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.015497\n","Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.046611\n","Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.000963\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-5c96a8fcf5d6>\u001b[0m in \u001b[0;36m<cell line: 210>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-1-5c96a8fcf5d6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-5c96a8fcf5d6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# print(data.shape, target.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 4 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["!pip install torchinfo\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import StepLR\n","from matplotlib import pyplot as plt\n","from torchinfo import summary\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.cnt = 0\n","        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(9216, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        # print(\"Input Shape\", x.shape)\n","        x = self.conv1(x)\n","        if not self.training:\n","          # print(self.cnt)\n","          # print(type(x), x.shape)\n","          if self.cnt % 5 == 0:\n","              print(\"AFTER CONV SHAPE\", x.shape)\n","              print(self.conv1.weight.dtype)\n","              print(self.conv1.weight.shape)\n","\n","              cur_x = x.cpu().detach().numpy()\n","              ax = plt.subplot(2, 2, 1)\n","              cur_w = self.conv1.weight.data.cpu().detach().numpy()\n","              print(cur_w[0, :, :, :])\n","              plt.imshow(cur_x[0, 0, :, :].reshape(26, 26), cmap=\"gray_r\")\n","              plt.xticks([])\n","              plt.yticks([])\n","\n","              ax = plt.subplot(2, 2, 2)\n","              print(cur_w[1, :, :, :])\n","              plt.imshow(cur_x[0, 1, :, :].reshape(26, 26), cmap=\"gray_r\")\n","              plt.xticks([])\n","              plt.yticks([])\n","\n","              ax = plt.subplot(2, 2, 3)\n","              print(cur_w[2, :, :, :])\n","              plt.imshow(cur_x[0, 2, :, :].reshape(26, 26), cmap=\"gray_r\")\n","              plt.xticks([])\n","              plt.yticks([])\n","\n","              ax = plt.subplot(2, 2, 4)\n","              print(cur_w[3, :, :, :])\n","              plt.imshow(cur_x[0, 3, :, :].reshape(26, 26), cmap=\"gray_r\")\n","              plt.xticks([])\n","              plt.yticks([])\n","              plt.savefig('input.png', dpi=1200)\n","\n","              # print(x)\n","        x = F.relu(x)\n","\n","        if not self.training:\n","          # print(self.cnt)\n","          # print(type(x), x.shape)\n","          if self.cnt % 5 == 0:\n","              print(\"AFTER CONV SHAPE\", x.shape)\n","              print(self.conv1.weight.dtype)\n","              print(self.conv1.weight.shape)\n","\n","              cur_x = x.cpu().detach().numpy()\n","              ax = plt.subplot(2, 2, 1)\n","              cur_w = self.conv1.weight.data.cpu().detach().numpy()\n","              print(cur_w[0, :, :, :])\n","              plt.imshow(cur_x[0, 0, :, :].reshape(26, 26), cmap=\"gray_r\")\n","              plt.xticks([])\n","              plt.yticks([])\n","\n","              ax = plt.subplot(2, 2, 2)\n","              print(cur_w[1, :, :, :])\n","              plt.imshow(cur_x[0, 1, :, :].reshape(26, 26), cmap=\"gray_r\")\n","              plt.xticks([])\n","              plt.yticks([])\n","\n","              ax = plt.subplot(2, 2, 3)\n","              print(cur_w[2, :, :, :])\n","              plt.imshow(cur_x[0, 2, :, :].reshape(26, 26), cmap=\"gray_r\")\n","              plt.xticks([])\n","              plt.yticks([])\n","\n","              ax = plt.subplot(2, 2, 4)\n","              print(cur_w[3, :, :, :])\n","              plt.imshow(cur_x[0, 3, :, :].reshape(26, 26), cmap=\"gray_r\")\n","              plt.xticks([])\n","              plt.yticks([])\n","              plt.savefig('relu.png', dpi=1200)\n","              # print(x)\n","          self.cnt += 1\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        output = F.log_softmax(x, dim=1)\n","        return output\n","\n","\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        # print(data.shape, target.shape)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 10 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","            if False:\n","                break\n","\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","\n","def main():\n","    # Training settings\n","    use_cuda = True\n","    use_mps = False\n","    train_batch_size = 64\n","    test_batch_size = 1000\n","    gamma = 0.7\n","    lr = 1.0\n","    momentum = 0.5\n","    seed = 1\n","    log_interval = 10\n","    epochs = 14\n","\n","    # Random seed\n","    torch.manual_seed(seed)\n","\n","\n","\n","    if use_cuda:\n","        device = torch.device(\"cuda\")\n","    elif use_mps:\n","        device = torch.device(\"mps\")\n","    else:\n","        device = torch.device(\"cpu\")\n","\n","    train_kwargs = {'batch_size': train_batch_size}\n","    test_kwargs = {'batch_size': test_batch_size}\n","    if use_cuda:\n","        cuda_kwargs = {'num_workers': 1,\n","                       'pin_memory': True,\n","                       'shuffle': True}\n","        train_kwargs.update(cuda_kwargs)\n","        test_kwargs.update(cuda_kwargs)\n","\n","    transform=transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,))\n","        ])\n","    dataset1 = datasets.MNIST('../data', train=True, download=True,\n","                       transform=transform)\n","    dataset2 = datasets.MNIST('../data', train=False,\n","                       transform=transform)\n","    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n","    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n","\n","    model = Net().to(device)\n","    summary(model, input_size=(test_batch_size, 1, 28, 28))\n","    optimizer = optim.Adadelta(model.parameters(), lr=lr)\n","\n","    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n","    for epoch in range(1, epochs + 1):\n","        train(model, device, train_loader, optimizer, epoch)\n","        test(model, device, test_loader)\n","        scheduler.step()\n","\n","    if True:\n","        torch.save(model.state_dict(), \"mnist_cnn.pt\")\n","\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","source":["!pip install torchviz\n","import torch\n","from torchviz import make_dot\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"m9Iiy7iU-OgV","executionInfo":{"status":"ok","timestamp":1739008478207,"user_tz":0,"elapsed":105436,"user":{"displayName":"Ђорђе Живановић","userId":"06601775518800841362"}},"outputId":"6e852bbf-7431-4851-9cb4-cdd00794b119"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchviz\n","  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.5.1+cu124)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchviz)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchviz)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchviz)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchviz)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchviz)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchviz)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchviz)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchviz)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchviz)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchviz)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n","Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchviz-0.0.3\n"]},{"output_type":"execute_result","data":{"text/plain":["'neural_network_graph.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(9216, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        output = F.log_softmax(x, dim=1)\n","        return output\n","\n","# Instantiate model\n","model = Net()\n","\n","# Create dummy input (batch_size=1, 1 channel, 28x28 image)\n","dummy_input = torch.randn(1, 1, 28, 28)\n","\n","# Generate computation graph\n","output = model(dummy_input)\n","graph = make_dot(output, params=dict(model.named_parameters()))\n","\n","# Save and display graph\n","graph.render(\"neural_network_graph\", format=\"png\")"],"metadata":{"id":"nGauFzoR-9XT","executionInfo":{"status":"ok","timestamp":1739008499085,"user_tz":0,"elapsed":77,"user":{"displayName":"Ђорђе Живановић","userId":"06601775518800841362"}},"outputId":"00fb3712-4b26-48c3-adbc-cddfa313885e","colab":{"base_uri":"https://localhost:8080/","height":35}},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'neural_network_graph.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]}]}